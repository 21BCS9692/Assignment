{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyO/HZ3oeFhDsbVqUlmd/Ugc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/21BCS9692/Assignment/blob/main/credit-card-fraud.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('creditcard.csv')\n",
        "\n",
        "# Basic info\n",
        "print(df.info())\n",
        "print(df.describe())\n",
        "\n",
        "# Check for missing values\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Class distribution\n",
        "print(df['Class'].value_counts())\n",
        "sns.countplot(x='Class', data=df)\n",
        "plt.title('Class Distribution')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NmNqt9Ds-K5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature engineering\n",
        "\n",
        "# Create time-based features\n",
        "df['hour'] = df['Time'].apply(lambda x: np.floor(x / 3600) % 24)\n",
        "df['day'] = df['Time'].apply(lambda x: np.floor(x / (3600 * 24)))\n",
        "\n",
        "# Transaction frequency features\n",
        "df['tx_freq_1h'] = df.groupby('hour')['Amount'].transform('count')\n",
        "df['tx_freq_24h'] = df.groupby('day')['Amount'].transform('count')\n",
        "\n",
        "# Amount statistics\n",
        "df['avg_amount_1h'] = df.groupby('hour')['Amount'].transform('mean')\n",
        "df['max_amount_1h'] = df.groupby('hour')['Amount'].transform('max')"
      ],
      "metadata": {
        "id": "TRLeRR0r-hi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows with NaN in either X_train or y_train\n",
        "nan_mask = X_train.isna().any(axis=1) | y_train.isna()\n",
        "X_train_clean = X_train[~nan_mask]\n",
        "y_train_clean = y_train[~nan_mask]\n",
        "\n",
        "print(f\"Removed {nan_mask.sum()} rows with NaN values\")\n",
        "print(f\"New shapes - X: {X_train_clean.shape}, y: {y_train_clean.shape}\")"
      ],
      "metadata": {
        "id": "Y-hb636qH6fL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to numpy array for infinite check\n",
        "X_np = X_train_clean.select_dtypes(include=[np.number]).to_numpy()\n",
        "print(f\"Infinite values in X_train: {np.isinf(X_np).sum()}\")"
      ],
      "metadata": {
        "id": "8bH8SakGH-LT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nData types:\")\n",
        "print(X_train_clean.dtypes)\n",
        "print(f\"\\ny_train type: {type(y_train_clean)}\")"
      ],
      "metadata": {
        "id": "C83_h41MH_A8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure all features are numeric\n",
        "X_train_final = X_train_clean.select_dtypes(include=[np.number])\n",
        "y_train_final = y_train_clean.astype(int)  # Ensure target is integer\n",
        "\n",
        "# Verify no nulls remain\n",
        "assert not X_train_final.isna().any().any()\n",
        "assert not y_train_final.isna().any()"
      ],
      "metadata": {
        "id": "jTP__MgrH_k9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure all features are numeric\n",
        "X_train_final = X_train_clean.select_dtypes(include=[np.number])\n",
        "y_train_final = y_train_clean.astype(int)  # Ensure target is integer\n",
        "\n",
        "# Verify no nulls remain\n",
        "assert not X_train_final.isna().any().any()\n",
        "assert not y_train_final.isna().any()"
      ],
      "metadata": {
        "id": "vdxSe8BuIK7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "try:\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_res, y_res = smote.fit_resample(X_train_final, y_train_final)\n",
        "    print(\"\\nSMOTE successful!\")\n",
        "    print(f\"Resampled shapes - X: {X_res.shape}, y: {y_res.shape}\")\n",
        "    print(\"Class distribution:\", pd.Series(y_res).value_counts())\n",
        "except Exception as e:\n",
        "    print(f\"\\nSMOTE failed with error: {str(e)}\")\n",
        "    print(\"Troubleshooting steps:\")\n",
        "    print(\"1. Ensure all values are finite (run np.isfinite(X_train_final.to_numpy()).all())\")\n",
        "    print(\"2. Verify y has exactly 2 classes:\", np.unique(y_train_final))"
      ],
      "metadata": {
        "id": "otupBwn8ILVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Final validation:\")\n",
        "print(\"NaN in X:\", X_res.isna().sum().sum())\n",
        "print(\"NaN in y:\", y_res.isna().sum())\n",
        "print(\"Class balance:\", y_res.value_counts())"
      ],
      "metadata": {
        "id": "mYxRDTOkIUFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(X_res.iloc[:, 0], X_res.iloc[:, 1], c=y_res)\n",
        "plt.title(\"Resampled Data\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6VBSGbpnIUjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Reload your data with forced numeric conversion\n",
        "df = pd.read_csv('creditcard.csv', engine='python')\n",
        "\n",
        "# Force-convert all features to numeric and drop problematic rows\n",
        "for col in df.columns:\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce')  # Convert non-numeric to NaN\n",
        "\n",
        "df = df.dropna()  # Remove ALL rows with any NaN values\n",
        "X = df.drop('Class', axis=1)\n",
        "y = df['Class'].astype(int)  # Critical: ensure target is integer (0/1)\n",
        "\n",
        "print(f\"Final clean data: {X.shape[0]} samples\")\n",
        "print(\"Class balance:\\n\", y.value_counts())"
      ],
      "metadata": {
        "id": "mjWj7xNwIq0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import resample\n",
        "\n",
        "# Split data first (avoid data leakage)\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Manual oversampling (works when SMOTE fails)\n",
        "fraud = X_train[y_train == 1]\n",
        "non_fraud = X_train[y_train == 0]\n",
        "\n",
        "fraud_upsampled = resample(fraud,\n",
        "                          replace=True,  # Important for oversampling\n",
        "                          n_samples=len(non_fraud),  # Match majority class\n",
        "                          random_state=42)\n",
        "\n",
        "X_res = pd.concat([non_fraud, fraud_upsampled])\n",
        "y_res = pd.Series([0]*len(non_fraud) + [1]*len(fraud_upsampled))\n",
        "\n",
        "print(\"\\nResampling successful!\")\n",
        "print(f\"New class balance:\\n{y_res.value_counts()}\")"
      ],
      "metadata": {
        "id": "h8QLQ29ZIzcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "model = RandomForestClassifier(class_weight='balanced', random_state=42)  # Extra protection\n",
        "model.fit(X_res, y_res)\n",
        "\n",
        "# Evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"\\nModel Performance:\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "DLpz1YFcI0Kt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nSanity Checks:\")\n",
        "print(\"NaN in X_res:\", X_res.isna().sum().sum())\n",
        "print(\"NaN in y_res:\", y_res.isna().sum())\n",
        "print(\"X dtypes:\\n\", X_res.dtypes)\n",
        "print(\"Unique classes in y:\", np.unique(y_res))"
      ],
      "metadata": {
        "id": "1SuzHDfCI0jO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_res.to_csv('X_resampled.csv', index=False)\n",
        "y_res.to_csv('y_resampled.csv', index=False)"
      ],
      "metadata": {
        "id": "5OQBnmLyKt6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# 1. Data Loading and Initial Exploration\n",
        "df = pd.read_csv('creditcard.csv')\n",
        "print(df.info())\n",
        "print(df.describe())\n",
        "print(df.isnull().sum())\n",
        "print(df['Class'].value_counts())\n",
        "\n",
        "# 2. Feature Engineering\n",
        "df['hour'] = df['Time'].apply(lambda x: np.floor(x / 3600) % 24)\n",
        "df['day'] = df['Time'].apply(lambda x: np.floor(x / (3600 * 24)))\n",
        "df['tx_freq_1h'] = df.groupby('hour')['Amount'].transform('count')\n",
        "df['tx_freq_24h'] = df.groupby('day')['Amount'].transform('count')\n",
        "df['avg_amount_1h'] = df.groupby('hour')['Amount'].transform('mean')\n",
        "df['max_amount_1h'] = df.groupby('hour')['Amount'].transform('max')\n",
        "\n",
        "# 3. Data Cleaning\n",
        "df = df.dropna()\n",
        "X = df.drop('Class', axis=1)\n",
        "y = df['Class'].astype(int)\n",
        "\n",
        "# 4. Train-Test Split (THIS MUST COME BEFORE ANY X_train/y_train OPERATIONS)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 5. Handle Missing Values (Now we can use X_train/y_train)\n",
        "nan_mask = X_train.isna().any(axis=1) | y_train.isna()\n",
        "X_train_clean = X_train[~nan_mask]\n",
        "y_train_clean = y_train[~nan_mask]\n",
        "\n",
        "# 6. Resampling\n",
        "try:\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_res, y_res = smote.fit_resample(X_train_clean, y_train_clean)\n",
        "except Exception as e:\n",
        "    print(f\"SMOTE failed: {e}\")\n",
        "    # Manual resampling fallback\n",
        "    fraud = X_train_clean[y_train_clean == 1]\n",
        "    non_fraud = X_train_clean[y_train_clean == 0]\n",
        "    fraud_upsampled = resample(fraud, replace=True, n_samples=len(non_fraud), random_state=42)\n",
        "    X_res = pd.concat([non_fraud, fraud_upsampled])\n",
        "    y_res = pd.Series([0]*len(non_fraud) + [1]*len(fraud_upsampled))\n",
        "\n",
        "# 7. Model Training\n",
        "model = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
        "model.fit(X_res, y_res)\n",
        "\n",
        "# 8. Evaluation\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# 9. Save Results\n",
        "X_res.to_csv('X_resampled.csv', index=False)\n",
        "y_res.to_csv('y_resampled.csv', index=False)"
      ],
      "metadata": {
        "id": "bnhPUaNRTUTp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}